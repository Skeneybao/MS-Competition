{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataProcessor import Data_Processor\n",
    "from DataProcessor import clean\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models import Word2Vec\n",
    "import pickle\n",
    "\n",
    "w2v_model = Word2Vec.load('/Users/yunzehui/Desktop/Morgan Stanley_Zehui/Sentiment_Prediction_Model-LSTM/model.w2v')\n",
    "model = load_model('/Users/yunzehui/Desktop/Morgan Stanley_Zehui/Sentiment_Prediction_Model-LSTM/model.h5') \n",
    "with open('/Users/yunzehui/Desktop/Morgan Stanley_Zehui/Sentiment_Prediction_Model-LSTM/tokenizer.pkl', 'rb') as handle: tokenizer = pickle.load(handle) \n",
    "with open('/Users/yunzehui/Desktop/Morgan Stanley_Zehui/Sentiment_Prediction_Model-LSTM/encoder.pkl', 'rb') as handle: encoder = pickle.load(handle)\n",
    "\n",
    "SEQUENCE_LENGTH = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENTIMENT\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
    "\n",
    "def decode_sentiment(score, include_neutral=True):\n",
    "    if include_neutral:        \n",
    "        label = NEUTRAL\n",
    "        if score <= SENTIMENT_THRESHOLDS[0]:\n",
    "            label = NEGATIVE\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1]:\n",
    "            label = POSITIVE\n",
    "\n",
    "        return label\n",
    "    else:\n",
    "        return NEGATIVE if score < 0.5 else POSITIVE\n",
    "    \n",
    "def predict(text_list_processed, include_neutral=True):\n",
    "    start_at = time.time()\n",
    "    result = pd.DataFrame(columns=['text', 'label', 'score', 'elapsed_time'])\n",
    "    for text in text_list_processed:\n",
    "        # Tokenize text\n",
    "        x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n",
    "        # Predict\n",
    "        score = model.predict([x_test])[0]\n",
    "        # Decode sentiment\n",
    "        label = decode_sentiment(score, include_neutral=include_neutral)\n",
    "        elapsed_time = time.time()-start_at\n",
    "        result = result.append(pd.DataFrame({'text':[text],'label':[label],'score':[float(score)],'elapsed_time':[elapsed_time]}),ignore_index=True)\n",
    "    return result  \n",
    "\n",
    "def datelist(start_month, end_month):\n",
    "    start_year = int(start_month[:4])\n",
    "    start_month = int(start_month[-2:])\n",
    "    end_year = int(end_month[:4])\n",
    "    end_month = int(end_month[-2:])\n",
    "    if start_year == end_year:\n",
    "        month_range = range(start_month, end_month + 1)\n",
    "        date_list = [\"{year}-{month:0=2d}\".format(year=str(start_year), month=M) for M in month_range]\n",
    "        return date_list\n",
    "    year_range = range(start_year + 1, end_year)\n",
    "    start_year_month_range = range(start_month, 13)\n",
    "    end_year_month_range = range(1, end_month + 1)\n",
    "    date_list = [\"{year}-{month:0=2d}\".format(year=str(start_year), month=M) for M in start_year_month_range]\n",
    "    date_list += [\"{year}-{month:0=2d}\".format(year=str(Y), month=M) for Y in year_range for M in range(1, 13)]\n",
    "    date_list += [\"{year}-{month:0=2d}\".format(year=str(end_year), month=M) for M in end_year_month_range]\n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discount Brokerage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([5905, 4595, 5955, 4689, 6305, 5638, 7616, 6629, 6886, 6730, 7852, 6228, 7225, 5338, 5014, 5777, 8095, 5153, 5648, 5986, 5346, 5183, 7338, 8259, 7059, 6153, 4725, 5025, 9961, 8858, 5964, 6177, 6385, 9195, 8665, 8516], 236073)\n",
      "([2573, 1914, 2732, 2013, 2766, 2355, 3286, 2926, 3850, 3784, 4184, 2982, 3863, 2330, 2436, 3307, 3892, 2590, 2957, 2673, 2539, 2588, 3610, 4146, 4296, 2829, 2404, 2411, 4871, 4125, 2875, 3392, 3677, 6142, 5324, 5329], 119971)\n"
     ]
    }
   ],
   "source": [
    "start_month='2017-06'\n",
    "end_month='2020-05'\n",
    "\n",
    "DP=Data_Processor(start_month, end_month,\n",
    "                  template=[\"Data/Discount Brokerage/Charles Schwab/CharlesSchwab\",\"Data/Discount Brokerage/TD Ameritrade/TDAmeritrade\"])\n",
    "DP.readdata()\n",
    "print(DP.datanums())\n",
    "DP.specifylang()\n",
    "DP.removenoise() \n",
    "DP.clean()\n",
    "DP.tokenizetext()\n",
    "print(DP.datanums())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DP.textdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = datelist(start_month, end_month)\n",
    "filepath=[]\n",
    "for i in range(len(dl)):\n",
    "    pathi = 'result/Discount Brokerage/'+dl[i]+'.json'\n",
    "    filepath.append(pathi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06  completed\n",
      "2017-07  completed\n",
      "2017-08  completed\n",
      "2017-09  completed\n",
      "2017-10  completed\n",
      "2017-11  completed\n",
      "2017-12  completed\n",
      "2018-01  completed\n",
      "2018-02  completed\n",
      "2018-03  completed\n",
      "2018-04  completed\n",
      "2018-05  completed\n",
      "2018-06  completed\n",
      "2018-07  completed\n",
      "2018-08  completed\n",
      "2018-09  completed\n",
      "2018-10  completed\n",
      "2018-11  completed\n",
      "2018-12  completed\n",
      "2019-01  completed\n",
      "2019-02  completed\n",
      "2019-03  completed\n",
      "2019-04  completed\n",
      "2019-05  completed\n",
      "2019-06  completed\n",
      "2019-07  completed\n",
      "2019-08  completed\n",
      "2019-09  completed\n",
      "2019-10  completed\n",
      "2019-11  completed\n",
      "2019-12  completed\n",
      "2020-01  completed\n",
      "2020-02  completed\n",
      "2020-03  completed\n",
      "2020-04  completed\n",
      "2020-05  completed\n"
     ]
    }
   ],
   "source": [
    "# run 1 time\n",
    "for i in range(len(dl)):\n",
    "    result = predict(DP.textdata()[dl[i]])\n",
    "    with open(filepath[i],\"w\") as f:\n",
    "        json.dump(result.to_json(),f)\n",
    "        print(dl[i], \" completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robo Advisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([6253, 6252, 6243, 6807, 6834, 7011, 6094, 7044, 7384, 6534, 5531, 4156, 3715, 3603, 3364, 2667, 3516, 2997, 5211, 3913, 3327, 4114, 3736], 116306)\n",
      "([1701, 1812, 1712, 1714, 1887, 1599, 1433, 1726, 2204, 1801, 1239, 1241, 1036, 1101, 991, 820, 1259, 900, 1264, 964, 849, 917, 750], 30920)\n"
     ]
    }
   ],
   "source": [
    "start_month='2017-06'\n",
    "end_month='2019-04'\n",
    "#end_month='2020-05'\n",
    "\n",
    "DP_robo=Data_Processor(start_month, end_month,\n",
    "                  template=[\"Data/Robo/Betterment/Betterment\",\"Data/Robo/Robo Advisor/RoboAdvisor\",\"Data/Robo/wealthfront/Wealthfront\"])\n",
    "DP_robo.readdata()\n",
    "print(DP_robo.datanums())\n",
    "DP_robo.specifylang()\n",
    "DP_robo.removenoise() \n",
    "DP_robo.clean()\n",
    "DP_robo.tokenizetext()\n",
    "print(DP_robo.datanums())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = datelist(start_month, end_month)\n",
    "filepath=[]\n",
    "for i in range(len(dl)):\n",
    "    pathi = 'result/Robo/'+dl[i]+'.json'\n",
    "    filepath.append(pathi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06  completed\n",
      "2017-07  completed\n",
      "2017-08  completed\n",
      "2017-09  completed\n",
      "2017-10  completed\n",
      "2017-11  completed\n",
      "2017-12  completed\n",
      "2018-01  completed\n",
      "2018-02  completed\n",
      "2018-03  completed\n",
      "2018-04  completed\n",
      "2018-05  completed\n",
      "2018-06  completed\n",
      "2018-07  completed\n",
      "2018-08  completed\n",
      "2018-09  completed\n",
      "2018-10  completed\n",
      "2018-11  completed\n",
      "2018-12  completed\n",
      "2019-01  completed\n",
      "2019-02  completed\n",
      "2019-03  completed\n",
      "2019-04  completed\n"
     ]
    }
   ],
   "source": [
    "# run 1 time\n",
    "for i in range(len(dl)):\n",
    "    result = predict(DP_robo.textdata()[dl[i]])\n",
    "    with open(filepath[i],\"w\") as f:\n",
    "        json.dump(result.to_json(),f)\n",
    "        print(dl[i], \" completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Brokerage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([20009, 20097, 19703, 19975, 20279, 20266, 20179, 20251, 20389, 20072, 19927, 19586, 19379, 19780, 20081, 20371, 20156, 20222, 19774, 19947, 20409, 20379, 20188, 20448, 19625, 20097, 19771, 19770, 19962, 19550, 18159, 19838, 19513, 20402, 20326, 20333], 719213)\n",
      "([6307, 5950, 6118, 6900, 6554, 7237, 6919, 7737, 7275, 7332, 7392, 7067, 7892, 7912, 7503, 8228, 8442, 8109, 8331, 8556, 8928, 9044, 9871, 9840, 10535, 10530, 9920, 9680, 10326, 10783, 9700, 9711, 9695, 10573, 11293, 10237], 308427)\n"
     ]
    }
   ],
   "source": [
    "start_month='2017-06'\n",
    "end_month='2020-05'\n",
    "\n",
    "DP_bank=Data_Processor(start_month, end_month,\n",
    "                  template=[\"Data/Bank Brokerage/JPMorgan/JPMorgan\",\"Data/Bank Brokerage/Wells Fargo/WellsFargo\"])\n",
    "DP_bank.readdata()\n",
    "print(DP_bank.datanums())\n",
    "DP_bank.specifylang()\n",
    "DP_bank.removenoise() \n",
    "DP_bank.clean()\n",
    "DP_bank.tokenizetext()\n",
    "print(DP_bank.datanums())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = datelist(start_month, end_month)\n",
    "filepath=[]\n",
    "for i in range(len(dl)):\n",
    "    pathi = 'result/Bank Brokerage/'+dl[i]+'.json'\n",
    "    filepath.append(pathi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06  completed\n",
      "2017-07  completed\n",
      "2017-08  completed\n",
      "2017-09  completed\n",
      "2017-10  completed\n",
      "2017-11  completed\n",
      "2017-12  completed\n",
      "2018-01  completed\n",
      "2018-02  completed\n",
      "2018-03  completed\n",
      "2018-04  completed\n",
      "2018-05  completed\n",
      "2018-06  completed\n",
      "2018-07  completed\n",
      "2018-08  completed\n",
      "2018-09  completed\n",
      "2018-10  completed\n",
      "2018-11  completed\n",
      "2018-12  completed\n",
      "2019-01  completed\n",
      "2019-02  completed\n",
      "2019-03  completed\n",
      "2019-04  completed\n",
      "2019-05  completed\n",
      "2019-06  completed\n",
      "2019-07  completed\n",
      "2019-08  completed\n",
      "2019-09  completed\n",
      "2019-10  completed\n",
      "2019-11  completed\n",
      "2019-12  completed\n",
      "2020-01  completed\n",
      "2020-02  completed\n",
      "2020-03  completed\n",
      "2020-04  completed\n",
      "2020-05  completed\n"
     ]
    }
   ],
   "source": [
    "# run 1 time\n",
    "for i in range(len(dl)):\n",
    "    result = predict(DP_bank.textdata()[dl[i]])\n",
    "    with open(filepath[i],\"w\") as f:\n",
    "        json.dump(result.to_json(),f)\n",
    "        print(dl[i], \" completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Brokerage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([11860, 11500, 11927, 11787, 11803, 12001, 11953, 13008, 11282, 10505, 10880, 11868, 12213, 11008, 12065, 11880, 11241, 11136, 11461, 10797, 11461, 11374, 10769, 11536, 11178, 10602, 11151, 10920, 11474, 10564, 10199, 10514, 10625, 11361, 10676, 11321], 407900)\n",
      "([2538, 2805, 3250, 2888, 2799, 2892, 2915, 3276, 2602, 2400, 2496, 3404, 3163, 2475, 2697, 3379, 2725, 2333, 2825, 2296, 2639, 3213, 2627, 3287, 3290, 1965, 2543, 3008, 2548, 2763, 2591, 2683, 2670, 2970, 2923, 3250], 101128)\n"
     ]
    }
   ],
   "source": [
    "start_month='2017-06'\n",
    "end_month='2020-05'\n",
    "\n",
    "# No Goldman Sacks \n",
    "DP_full=Data_Processor(start_month, end_month,\n",
    "                  template=[\"Data/Full Brokerage/Merrill Lynch/MerillLynch\",\"Data/Full Brokerage/Morgan_Stanley/Morgan_Stanley\"])\n",
    "DP_full.readdata()\n",
    "print(DP_full.datanums())\n",
    "DP_full.specifylang()\n",
    "DP_full.removenoise() \n",
    "DP_full.clean()\n",
    "DP_full.tokenizetext()\n",
    "print(DP_full.datanums())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = datelist(start_month, end_month)\n",
    "filepath=[]\n",
    "for i in range(len(dl)):\n",
    "    pathi = 'result/Full Brokerage/'+dl[i]+'.json'\n",
    "    filepath.append(pathi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06  completed\n",
      "2017-07  completed\n",
      "2017-08  completed\n",
      "2017-09  completed\n",
      "2017-10  completed\n",
      "2017-11  completed\n",
      "2017-12  completed\n",
      "2018-01  completed\n",
      "2018-02  completed\n",
      "2018-03  completed\n",
      "2018-04  completed\n",
      "2018-05  completed\n",
      "2018-06  completed\n",
      "2018-07  completed\n",
      "2018-08  completed\n",
      "2018-09  completed\n",
      "2018-10  completed\n",
      "2018-11  completed\n",
      "2018-12  completed\n",
      "2019-01  completed\n",
      "2019-02  completed\n",
      "2019-03  completed\n",
      "2019-04  completed\n",
      "2019-05  completed\n",
      "2019-06  completed\n",
      "2019-07  completed\n",
      "2019-08  completed\n",
      "2019-09  completed\n",
      "2019-10  completed\n",
      "2019-11  completed\n",
      "2019-12  completed\n",
      "2020-01  completed\n",
      "2020-02  completed\n",
      "2020-03  completed\n",
      "2020-04  completed\n",
      "2020-05  completed\n"
     ]
    }
   ],
   "source": [
    "# run 1 time\n",
    "for i in range(len(dl)):\n",
    "    result = predict(DP_full.textdata()[dl[i]])\n",
    "    with open(filepath[i],\"w\") as f:\n",
    "        json.dump(result.to_json(),f)\n",
    "        print(dl[i], \" completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

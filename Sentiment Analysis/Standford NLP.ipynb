{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandfordCoreNLP\n",
    "#### Use this API to get sentiment score (via PyCorenlp wrapper)\n",
    "\n",
    "See https://stackoverflow.com/questions/32879532/stanford-nlp-for-python\n",
    "\n",
    "Since StandfordCoreNLP is written in Java, we need to use pycorenlp (a python wrapper for StandfordCoreNLP) to connect to Java and use it here. To run the following codes, you need to install the following:\n",
    "\n",
    "1. Install latest StandfordCoreNLP version (a zip file) from http://nlp.stanford.edu/software/stanford-corenlp-latest.zip \n",
    "    - Note: In MacOS, you can directly download by using wget or curl\n",
    "\n",
    "2. Unzip the downloaded file, put it into a directory, say named `standford-corenlp-4.0.0`.\n",
    "\n",
    "3. Start the server using terminal\n",
    "    - Open the terminal, use `cd` to go to the directory you just created, type `cd Users\\xxx\\stanstandford-corenlp-4.0.0`\n",
    "    - Then type in `java -mx5g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -timeout 10000` \n",
    "    - Now you should see something like `[main] INFO CoreNLP - StanfordCoreNLPServer listening at /0:0:0:0:0:0:0:0:9000`, means that your server is started, waiting for data from port in 9000\n",
    "   \n",
    "4. Then download the `pycorenlp` package using `pip install pycorenlp` \n",
    "5. Now you should be good to run the following sentiment anaylsis code using StandfordCoreNLP (note the port below is also using 9000 as you just set. If port name not consistent, your code would fail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hwk97\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hwk97\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hwk97\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import string\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "import pprint\n",
    "\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Data_Processor import clean, Data_Processor\n",
    "\n",
    "from pycorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([9394, 11212, 15014, 12599, 12810], 61029)\n",
      "([4499, 5478, 9431, 7038, 7388], 33834)\n"
     ]
    }
   ],
   "source": [
    "DP=Data_Processor(start_month='2020-01',end_month='2020-05',\n",
    "                  template=[\"../../Data/FidelityInvestments\", \n",
    "                            \"../../Data/eTrade\",\n",
    "                            \"../../Data/CharlesSchwab\",\n",
    "                           \"../../Data/TDAmeritrade\"])\n",
    "\n",
    "DP.readdata()\n",
    "print(DP.datanums())\n",
    "DP.specifylang()\n",
    "DP.removenoise() \n",
    "DP.clean()\n",
    "\n",
    "#after removing noises (delete promotional/advertisement data)\n",
    "print(DP.datanums())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DP.tokenizetext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-01', '2020-02', '2020-03', '2020-04', '2020-05']\n"
     ]
    }
   ],
   "source": [
    "months = list(DP.textdata().keys())\n",
    "print(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_data= {}\n",
    "string_data = {}\n",
    "#remove token word with length<3\n",
    "for m in months:\n",
    "    token_data[m] = [[word for word in sent.split() if len(word)>=3] for sent in DP.textdata()[m]]\n",
    "    string_data[m] = [\" \".join([word for word in token]) for token in token_data[m]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['think woman biggest influencer abigail johnson fidelity investment', 'sure fidelity investment super supportive employee time', 'untrue laughable robinhood founded disrupted discount brokerage space providing commissionfree trading forcing incumbent retail broker charles schwab corp ameritrade holding corp fidelity investment follow suit']\n"
     ]
    }
   ],
   "source": [
    "#print(token_data['2020-05'][:3])\n",
    "print(string_data['2020-05'][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rket buy roku didnt get filled morning next thing know position blank etradepro totally unresponsive never got fill roku run close back cash hour mattered\\nwhaaat dont know story\\nnever forget time etrade actually digitally mark account fucked roku fun phone call ever\\nthats saying told could trade paper money said wtf think usd mark\\ncomputer shouldnt problem maybe switch etrade\\ntrying explain tdameritrade would like digitally mark account balance ive shown jay powell interview dont get frustrating\\nliked webull account mess take month get response use ameritrade customer service good anywhere else account messed many time webull worth headache call\\ntdameritrade wonder used debit card buy stock\\nthats blowup think swim chart think swim free account ameritrade\\nmany financial institution use like fidelity tdameritrade talk broker option use app like acorn robinhood\\nfelt wrath robin hood traded month switched ameritrade loving highly recommend\\nameritrade use like havent used anything else clue'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentences = \"\\n\".join(string_data[m])  #join by '\\n'\n",
    "all_sentences[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7388 12 615\n",
      "processing 0 to 615\n",
      "processing 615 to 1230\n",
      "processing 1230 to 1845\n",
      "processing 1845 to 2460\n",
      "processing 2460 to 3075\n",
      "processing 3075 to 3690\n",
      "processing 3690 to 4305\n",
      "processing 4305 to 4920\n",
      "processing 4920 to 5535\n",
      "processing 5535 to 6150\n",
      "processing 6150 to 6765\n",
      "processing 6765 to 7380\n"
     ]
    }
   ],
   "source": [
    "LIMIT = 100000 #standfordnlp can only process 100000 characters a time, need divide them into serveral parts\n",
    "n_divid = len(all_sentences)//LIMIT*2\n",
    "len_divid = len(string_data[m])//n_divid\n",
    "print(len(string_data[m]), n_divid, len_divid)\n",
    "\n",
    "nlp = StanfordCoreNLP('http://localhost:9000') #the port here should be the same as above (openned server)\n",
    "#nlp.annotate will return a dictionary (key is 'sentences')\n",
    "\n",
    "#here nlp.annotate process each sentence in the paragraph above using the annotators specified below\n",
    "\n",
    "res = {}\n",
    "sentiment = []\n",
    "\n",
    "for i in range(n_divid):\n",
    "    print(f\"processing {i*len_divid} to {(i+1)*len_divid}\")\n",
    "    sentence = \". \".join(string_data[m][i*len_divid:(i+1)*len_divid])\n",
    "    \n",
    "    res[i] = nlp.annotate(sentence,\n",
    "                   properties={\n",
    "                       'annotators': 'tokenize,ssplit,pos,parse,sentiment',\n",
    "                       'outputFormat': 'json',\n",
    "                       'timeout': 100000,\n",
    "                   })\n",
    "    if isinstance(res[i],str):\n",
    "        raise Exception(\"Sentence is too long to parse\")\n",
    "    \n",
    "    #add sentiment result\n",
    "    else:\n",
    "        for s in res[i]['sentences']:\n",
    "            sentiment.append([\" \".join([t[\"word\"] for t in s[\"tokens\"]])[:-2], s[\"sentimentValue\"], s[\"sentiment\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.DataFrame(sentiment, columns=['text', 'score', 'sentiment'])\n",
    "sentiment_df['score'] = sentiment_df['score'].astype(int)\n",
    "positive_df = sentiment_df[sentiment_df['score']>=3]\n",
    "negative_df = sentiment_df[sentiment_df['score']<=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2       untrue laughable robinhood founded disrupted d...\n",
       "9       chinmay thank interest fidelity investment off...\n",
       "10      dan nathan liberal political hack writing far ...\n",
       "13      rep pat toomey rpa accepted fidelity investmen...\n",
       "19      weird wildly date tweet promoted timeline fide...\n",
       "                              ...                        \n",
       "7341    course never actually held stock disagreement ...\n",
       "7344        ridiculous happened trying close tdameritrade\n",
       "7345    get phone middle day they re clearly freaking ...\n",
       "7346    quick october market buy roku did nt get fille...\n",
       "7348    never forget time etrade actually digitally ma...\n",
       "Name: text, Length: 2180, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA(texts, topics=10, num_words=15, dictionary = None):\n",
    "    if not dictionary:\n",
    "        dictionary = corpora.Dictionary(texts) # texts: list of list of words\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    num_topics = topics #The number of topics that should be generated\n",
    "    passes = 30\n",
    "    lda = LdaModel(corpus,\n",
    "              id2word=dictionary,\n",
    "              alpha = 'auto',\n",
    "              num_topics=num_topics,\n",
    "              passes=passes)\n",
    "    \n",
    "    return lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_token = [sent.split(\" \") for sent in negative_df['text']]\n",
    "positive_token = [sent.split(\" \") for sent in positive_df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda modeling 2020-05\n"
     ]
    }
   ],
   "source": [
    "lda_model = {}\n",
    "k = 10\n",
    "num_words = 15\n",
    "print(\"lda modeling\", m)\n",
    "#lda_model[m] = {}\n",
    "lda_pos = LDA(positive_token, topics=k, num_words=num_words)  #must use token_data [[word1,word2],[...]]\n",
    "lda_neg = LDA(negative_token, topics=k, num_words=num_words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.018*\"high\" + 0.018*\"good\" + 0.013*\"well\" + 0.013*\"time\" + '\n",
      "        '0.012*\"thanks\" + 0.011*\"got\" + 0.011*\"tdameritrade\" + 0.011*\"etrade\" '\n",
      "        '+ 0.010*\"schwab\" + 0.010*\"ameritrade\" + 0.009*\"charles\" + 0.009*\"day\" '\n",
      "        '+ 0.007*\"thing\" + 0.007*\"always\" + 0.006*\"know\"'),\n",
      "    (   1,\n",
      "        '0.022*\"tdameritrade\" + 0.016*\"update\" + 0.014*\"price\" + '\n",
      "        '0.010*\"signal\" + 0.008*\"premium\" + 0.008*\"thinkorswim\" + '\n",
      "        '0.007*\"right\" + 0.007*\"thanks\" + 0.007*\"street\" + 0.007*\"definitely\" '\n",
      "        '+ 0.007*\"half\" + 0.006*\"analyst\" + 0.006*\"wall\" + 0.006*\"excellent\" + '\n",
      "        '0.006*\"think\"'),\n",
      "    (   2,\n",
      "        '0.011*\"tdameritrade\" + 0.010*\"share\" + 0.008*\"job\" + 0.008*\"join\" + '\n",
      "        '0.008*\"case\" + 0.007*\"military\" + 0.007*\"real\" + 0.007*\"family\" + '\n",
      "        '0.007*\"part\" + 0.006*\"estate\" + 0.006*\"network\" + 0.006*\"year\" + '\n",
      "        '0.006*\"may\" + 0.006*\"great\" + 0.006*\"week\"'),\n",
      "    (   3,\n",
      "        '0.022*\"account\" + 0.021*\"ameritrade\" + 0.016*\"etrade\" + 0.016*\"like\" '\n",
      "        '+ 0.014*\"stock\" + 0.011*\"robinhood\" + 0.011*\"nt\" + 0.011*\"share\" + '\n",
      "        '0.010*\"get\" + 0.009*\"fidelity\" + 0.009*\"tdameritrade\" + 0.009*\"good\" '\n",
      "        '+ 0.009*\"use\" + 0.008*\"do\" + 0.008*\"buy\"'),\n",
      "    (   4,\n",
      "        '0.049*\"schwab\" + 0.040*\"charles\" + 0.014*\"challenge\" + 0.009*\"price\" '\n",
      "        '+ 0.009*\"way\" + 0.009*\"best\" + 0.008*\"tour\" + 0.008*\"right\" + '\n",
      "        '0.008*\"stock\" + 0.008*\"pga\" + 0.008*\"june\" + 0.007*\"love\" + '\n",
      "        '0.006*\"trade\" + 0.006*\"market\" + 0.006*\"service\"'),\n",
      "    (   5,\n",
      "        '0.035*\"thanks\" + 0.022*\"trading\" + 0.016*\"ameritrade\" + '\n",
      "        '0.015*\"platform\" + 0.014*\"tdameritrade\" + 0.013*\"great\" + '\n",
      "        '0.011*\"best\" + 0.009*\"account\" + 0.009*\"broker\" + 0.008*\"etrade\" + '\n",
      "        '0.008*\"get\" + 0.008*\"nt\" + 0.007*\"future\" + 0.007*\"check\" + '\n",
      "        '0.007*\"response\"'),\n",
      "    (   6,\n",
      "        '0.019*\"tdameritrade\" + 0.016*\"order\" + 0.013*\"ameritrade\" + '\n",
      "        '0.011*\"platform\" + 0.010*\"happy\" + 0.009*\"use\" + 0.009*\"day\" + '\n",
      "        '0.009*\"trading\" + 0.007*\"price\" + 0.007*\"stop\" + 0.007*\"great\" + '\n",
      "        '0.006*\"got\" + 0.006*\"forex\" + 0.006*\"find\" + 0.006*\"portfolio\"'),\n",
      "    (   7,\n",
      "        '0.019*\"account\" + 0.019*\"etrade\" + 0.015*\"new\" + 0.014*\"ameritrade\" + '\n",
      "        '0.014*\"trade\" + 0.013*\"thank\" + 0.012*\"please\" + 0.010*\"money\" + '\n",
      "        '0.010*\"tdameritrade\" + 0.009*\"day\" + 0.008*\"time\" + 0.007*\"call\" + '\n",
      "        '0.007*\"best\" + 0.007*\"still\" + 0.006*\"also\"'),\n",
      "    (   8,\n",
      "        '0.023*\"ameritrade\" + 0.016*\"tdameritrade\" + 0.013*\"love\" + '\n",
      "        '0.010*\"good\" + 0.009*\"recommend\" + 0.008*\"time\" + 0.008*\"option\" + '\n",
      "        '0.008*\"schwab\" + 0.007*\"platform\" + 0.007*\"would\" + 0.007*\"business\" '\n",
      "        '+ 0.007*\"better\" + 0.006*\"way\" + 0.006*\"etrade\" + 0.006*\"move\"'),\n",
      "    (   9,\n",
      "        '0.020*\"tdameritrade\" + 0.013*\"customer\" + 0.012*\"charlesschwab\" + '\n",
      "        '0.011*\"ameritrade\" + 0.011*\"use\" + 0.010*\"tos\" + 0.010*\"etrade\" + '\n",
      "        '0.008*\"mobile\" + 0.008*\"service\" + 0.008*\"love\" + 0.007*\"thinkorswim\" '\n",
      "        '+ 0.007*\"favorite\" + 0.007*\"app\" + 0.007*\"guy\" + 0.007*\"made\"')]\n"
     ]
    }
   ],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(lda_pos.print_topics(num_words=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.016*\"stock\" + 0.015*\"day\" + 0.012*\"trade\" + 0.011*\"schwab\" + '\n",
      "        '0.008*\"platform\" + 0.007*\"last\" + 0.007*\"ameritrade\" + 0.006*\"like\" + '\n",
      "        '0.006*\"think\" + 0.006*\"etrade\" + 0.006*\"year\" + 0.006*\"money\" + '\n",
      "        '0.006*\"charles\" + 0.006*\"every\" + 0.005*\"do\"'),\n",
      "    (   1,\n",
      "        '0.025*\"ameritrade\" + 0.018*\"stock\" + 0.016*\"account\" + 0.012*\"new\" + '\n",
      "        '0.011*\"tdameritrade\" + 0.009*\"first\" + 0.008*\"market\" + '\n",
      "        '0.008*\"online\" + 0.008*\"schwab\" + 0.008*\"robinhood\" + 0.007*\"saw\" + '\n",
      "        '0.007*\"etrade\" + 0.007*\"charles\" + 0.007*\"like\" + 0.007*\"use\"'),\n",
      "    (   2,\n",
      "        '0.023*\"stock\" + 0.021*\"schwab\" + 0.016*\"charles\" + '\n",
      "        '0.016*\"tdameritrade\" + 0.011*\"ameritrade\" + 0.009*\"would\" + '\n",
      "        '0.008*\"account\" + 0.007*\"bought\" + 0.007*\"market\" + 0.007*\"investor\" '\n",
      "        '+ 0.007*\"say\" + 0.007*\"investment\" + 0.006*\"charlesschwab\" + '\n",
      "        '0.006*\"oil\" + 0.005*\"open\"'),\n",
      "    (   3,\n",
      "        '0.025*\"etrade\" + 0.024*\"ameritrade\" + 0.019*\"use\" + 0.016*\"robinhood\" '\n",
      "        '+ 0.016*\"stock\" + 0.014*\"nt\" + 0.012*\"like\" + 0.012*\"account\" + '\n",
      "        '0.010*\"option\" + 0.010*\"do\" + 0.009*\"day\" + 0.009*\"time\" + '\n",
      "        '0.008*\"trading\" + 0.007*\"let\" + 0.007*\"know\"'),\n",
      "    (   4,\n",
      "        '0.014*\"etrade\" + 0.010*\"tdameritrade\" + 0.009*\"platform\" + '\n",
      "        '0.008*\"like\" + 0.007*\"future\" + 0.007*\"small\" + 0.007*\"signal\" + '\n",
      "        '0.007*\"ameritrade\" + 0.006*\"use\" + 0.006*\"etorous\" + 0.006*\"saxobank\" '\n",
      "        '+ 0.006*\"icmarket\" + 0.006*\"swissquoteuk\" + 0.006*\"fxproglobal\" + '\n",
      "        '0.006*\"adsslondon\"'),\n",
      "    (   5,\n",
      "        '0.014*\"ameritrade\" + 0.013*\"market\" + 0.008*\"two\" + 0.008*\"even\" + '\n",
      "        '0.008*\"around\" + 0.007*\"reality\" + 0.006*\"recovery\" + 0.006*\"etf\" + '\n",
      "        '0.006*\"news\" + 0.006*\"company\" + 0.005*\"check\" + 0.005*\"please\" + '\n",
      "        '0.005*\"stock\" + 0.005*\"tdameritrade\" + 0.005*\"ceo\"'),\n",
      "    (   6,\n",
      "        '0.026*\"tdameritrade\" + 0.021*\"trade\" + 0.019*\"app\" + 0.019*\"nt\" + '\n",
      "        '0.014*\"do\" + 0.014*\"ameritrade\" + 0.013*\"trading\" + 0.012*\"get\" + '\n",
      "        '0.011*\"money\" + 0.010*\"etrade\" + 0.010*\"day\" + 0.010*\"thinkorswim\" + '\n",
      "        '0.009*\"platform\" + 0.009*\"account\" + 0.008*\"time\"'),\n",
      "    (   7,\n",
      "        '0.020*\"tdameritrade\" + 0.019*\"etrade\" + 0.017*\"account\" + '\n",
      "        '0.012*\"trade\" + 0.011*\"call\" + 0.011*\"hold\" + 0.009*\"time\" + '\n",
      "        '0.009*\"not\" + 0.009*\"can\" + 0.009*\"money\" + 0.008*\"hour\" + '\n",
      "        '0.007*\"issue\" + 0.007*\"stock\" + 0.006*\"lost\" + 0.006*\"cant\"'),\n",
      "    (   8,\n",
      "        '0.026*\"tdameritrade\" + 0.014*\"order\" + 0.014*\"like\" + 0.011*\"etrade\" '\n",
      "        '+ 0.011*\"time\" + 0.009*\"nothing\" + 0.009*\"broker\" + 0.008*\"thanks\" + '\n",
      "        '0.008*\"stop\" + 0.007*\"position\" + 0.007*\"morning\" + '\n",
      "        '0.006*\"ameritrade\" + 0.006*\"able\" + 0.006*\"platform\" + '\n",
      "        '0.005*\"account\"'),\n",
      "    (   9,\n",
      "        '0.013*\"tdameritrade\" + 0.011*\"stock\" + 0.009*\"share\" + '\n",
      "        '0.008*\"screwed\" + 0.007*\"trading\" + 0.007*\"get\" + 0.007*\"account\" + '\n",
      "        '0.007*\"etrade\" + 0.006*\"schwab\" + 0.006*\"ive\" + 0.006*\"got\" + '\n",
      "        '0.005*\"bank\" + 0.005*\"last\" + 0.005*\"never\" + 0.005*\"see\"')]\n"
     ]
    }
   ],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(lda_neg.print_topics(num_words=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
